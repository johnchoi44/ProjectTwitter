{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNfmq65a1uJTb4ZnPG5f0XZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/johnchoi44/ProjectTwitter/blob/main/Working_TwitterIDSearch_Final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nUl5CEFsqFc-",
        "outputId": "2e7bca32-dd92-497f-a899-d957009f0e24"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "# êµ¬ê¸€ ë“œë¼ì´ë¸Œ ì—°ê²°\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# í•„ìš” ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜\n",
        "!pip install googlesearch-python\n",
        "!pip install xlsxwriter"
      ],
      "metadata": {
        "id": "KQAIqh65qIez",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee00d9c6-d9f4-4bc7-d7c1-87b3af259a35",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting googlesearch-python\n",
            "  Downloading googlesearch_python-1.2.4-py3-none-any.whl (4.5 kB)\n",
            "Requirement already satisfied: beautifulsoup4>=4.9 in /usr/local/lib/python3.10/dist-packages (from googlesearch-python) (4.12.3)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from googlesearch-python) (2.31.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4>=4.9->googlesearch-python) (2.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->googlesearch-python) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->googlesearch-python) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->googlesearch-python) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->googlesearch-python) (2024.6.2)\n",
            "Installing collected packages: googlesearch-python\n",
            "Successfully installed googlesearch-python-1.2.4\n",
            "Collecting xlsxwriter\n",
            "  Downloading XlsxWriter-3.2.0-py3-none-any.whl (159 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m159.9/159.9 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xlsxwriter\n",
            "Successfully installed xlsxwriter-3.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ë¼ì´ë¸ŒëŸ¬ë¦¬ import\n",
        "import pandas as pd\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from googlesearch import search as s\n",
        "import re\n",
        "from itertools import zip_longest\n",
        "import math"
      ],
      "metadata": {
        "id": "a_6gfGK-qMHR"
      },
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Code to get full URL\n",
        "import requests\n",
        "\n",
        "def unshorten_url(short_url):\n",
        "  if short_url == None:\n",
        "    return None\n",
        "  else:\n",
        "    try:\n",
        "      response = requests.get(short_url, allow_redirects=True)\n",
        "      return response.url\n",
        "    except:\n",
        "      return None"
      ],
      "metadata": {
        "id": "bLd4x9nJ8jg-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "number_count = 1\n",
        "# ê²€ìƒ‰ìš© variable ì„¤ì •\n",
        "twitterurl = \"https://twitter.com/\"\n",
        "company = \"Adam and Reese LLP\""
      ],
      "metadata": {
        "id": "HFHUIiacsGfA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1 (ì´ˆë°˜ì— í•œë²ˆë§Œ execute)\n",
        "\n",
        "# ë³€í˜¸ì‚¬ ì´ë¦„ ì—‘ì…€íŒŒì¼ì—ì„œ ë¶ˆëŸ¬ì™€ì„œ ë¦¬ìŠ¤íŠ¸ë¡œ ë§Œë“¤ê¸°\n",
        "lawyerurl = []\n",
        "path = \"/content/drive/MyDrive/Lawyers/Accounts/AdamandReese/AdamsandReese.csv\" # ê²½ë¡œ íšŒì‚¬ì— ë§ì¶° ë³€ê²½\n",
        "df = pd.read_csv(path)\n",
        "columns = [\"lawyer name\"]\n",
        "newdf = df[columns]\n",
        "\n",
        "csv_file_path = \"/content/drive/MyDrive/Lawyers/Accounts/AdamandReese/{} Twitter.csv\".format(company)\n",
        "newdf.to_csv(csv_file_path, index=False)"
      ],
      "metadata": {
        "id": "XzLOuMwgu9t8"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# search function defined\n",
        "def search_input(input_value):\n",
        "  lawyerurl = []\n",
        "  searchs = '{} {} Twitter'.format(company, input_value)\n",
        "  results = s(searchs, sleep_interval = 1, num_results = 1)\n",
        "  for r in results:\n",
        "    if r.startswith(twitterurl):\n",
        "      lawyerurl.append(r)\n",
        "  return lawyerurl"
      ],
      "metadata": {
        "id": "Tpcn96eGt0DD"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2 (í•œë²ˆ execute ì´í›„ Step 3 execute)\n",
        "\n",
        "# ì—‘ì…€íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°\n",
        "file_path = \"/content/drive/MyDrive/Lawyers/Accounts/AdamandReese/Adam and Reese LLP Twitter.csv\"\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "input_column = df.columns[0]\n",
        "\n",
        "outputs = []\n",
        "twitter_link = []\n",
        "pattern = r'\\d{19}'\n",
        "patterns = r'\\d{18}'\n",
        "for input_value in df[input_column]:\n",
        "  twitter_id = []\n",
        "  try:\n",
        "    output_value = search_input(input_value)\n",
        "\n",
        "    for i in output_value:\n",
        "      i = i.replace(\"https://twitter.com/\", \"\")\n",
        "      i = i.replace(\"/status/\",\"\")\n",
        "      i = re.sub(r\"\\?lang=[a-zA-Z]{2}\", \"\", i)\n",
        "      i = re.sub(pattern, \"\", i)\n",
        "      i = re.sub(patterns, \"\", i)\n",
        "      twitter_id.append(i)\n",
        "\n",
        "    for item in twitter_id[:]:\n",
        "      if 'adamsandreese' in item:\n",
        "          twitter_id.remove(item)\n",
        "\n",
        "    # check for empty list\n",
        "    if not twitter_id:\n",
        "      outputs.append('none')\n",
        "    else:\n",
        "      outputs.append(twitter_id)\n",
        "  except Exception as error:\n",
        "    print(\"An exception occured:\", error)\n",
        "    break\n",
        "\n",
        "print(outputs)\n",
        "# Add the results to the dataframe\n",
        "merged = list(zip_longest(df[input_column], outputs, fillvalue = None))\n",
        "df = pd.DataFrame(merged, columns=['lawyer name', 'twitter id'])\n",
        "\n",
        "# Write the updated dataframe back to the Excel file\n",
        "df.to_csv(file_path, index = False)"
      ],
      "metadata": {
        "id": "OQZr0lUTtS-H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "433ac992-8bc5-47b1-8ee2-6de7211e9576"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "An exception occured: 429 Client Error: Too Many Requests for url: https://www.google.com/sorry/index?continue=https://www.google.com/search%3Fq%3DAdam%252Band%252BReese%252BLLP%252BDonald%252BA.%252BMihokovich%252BTwitter%26num%3D3%26hl%3Den%26start%3D0%26safe%3Dactive&hl=en&q=EgQiqBnCGPqrt7QGIjD3vOtN4Rsj0_-IdiPNfGcIcVnuGQaAzSZdMgHgvMz9M7ukJjpp4hs4rdl391VPtWMyBWpjbmRyWgFD\n",
            "[['chuckadamsar'], 'none', ['richieaguilar88'], 'none', 'none', ['drlukeallen', 'coachacallen'], ['timanzenberger'], ['wtmatkinson', 'WTMAtkinson'], ['la_baio'], ['randyebarnett'], 'none', 'none', 'none', 'none', ['drjennybee'], 'none', ['dbernstein', 'davidlbernstein'], ['MarkBerson1'], 'none', 'none', 'none', 'none', 'none', 'none', ['cbbonner'], 'none', 'none', 'none', 'none', 'none', 'none', ['mattbruenig'], ['bennybriggs1'], 'none', 'none', 'none', ['taylorbrooks'], 'none', 'none', ['seanbuckley', 'attorneybuckley?lang=de'], 'none', 'none', ['bradleybyrne'], 'none', 'none', ['campbelladam79'], 'none', 'none', 'none', ['shadylawrence'], 'none', 'none', ['tnlastcall'], 'none', 'none', ['adamcopes', 'matt_copeland1'], 'none', 'none', 'none', 'none', 'none', ['attorneyjeremy1'], 'none', 'none', 'none', 'none', ['adzjt15', 'dart_adams'], ['JDavisOfficial'], ['superdavis78'], 'none', ['ginadtucker'], 'none', 'none', 'none', ['domianojl'], 'none', 'none', 'none', 'none', ['APD849'], 'none', 'none', 'none', 'none', 'none', ['ifcapdiesidie'], 'none', 'none', 'none', ['adamferrara'], 'none', 'none', ['andrufreeman', 'andrewfreemanpr?lang=bn'], 'none', 'none', ['reecegaines1', 'edgainesiii'], 'none', 'none', 'none', 'none', ['robgill_epic'], ['javgonz'], ['roscoegreeniii'], ['theadamgregory'], ['ProfGrewal'], 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', ['lmeltzerhenry'], ['randyhetrick'], 'none', 'none', ['sethpowerhood'], ['johnhooksMT'], 'none', 'none', ['azjackson85'], ['adamjohnsonchi'], ['davidjohnson31'], 'none', 'none', ['J_SamJones'], ['chris_d_joseph'], 'none', 'none', ['kearnsdavis'], 'none', 'none', 'none', 'none', 'none', ['reeses'], ['rosscoulthart'], 'none', 'none', 'none', ['aroselli89'], ['NewsLambert'], ['balampley79'], 'none', ['leduff_taylor'], ['rabbijosh'], ['oneadamreese'], 'none', 'none', 'none', 'none', 'none', 'none', ['robwestiii'], 'none', 'none', ['criticalmassey'], 'none', 'none', 'none', ['kokomo6253'], 'none', 'none', 'none', 'none', 'none', ['culturedmodesty'], 'none']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3\n",
        "\n",
        "# ì—‘ì…€íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°\n",
        "file_path = \"/content/drive/MyDrive/Lawyers/Accounts/AdamandReese/Adam and Reese LLP Twitter.csv\"\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "input_column = df.columns[0]\n",
        "output_column = df.columns[1]\n",
        "\n",
        "# get the count of the output column\n",
        "output_list = df[output_column]\n",
        "filtered_list = [item for item in output_list if not (isinstance(item, float) and math.isnan(item))]\n",
        "count = len(filtered_list)\n",
        "\n",
        "pattern = r'\\d{19}'\n",
        "patterns = r'\\d{18}'\n",
        "for input_value in df[input_column][count:]:\n",
        "  twitter_id = []\n",
        "  try:\n",
        "    output_value = search_input(input_value)\n",
        "\n",
        "    for i in output_value:\n",
        "      i = i.replace(\"https://twitter.com/\", \"\")\n",
        "      i = i.replace(\"/status/\",\"\")\n",
        "      i = re.sub(r\"\\?lang=[a-zA-Z]{2}\", \"\", i)\n",
        "      i = re.sub(pattern, \"\", i)\n",
        "      i = re.sub(patterns, \"\", i)\n",
        "      twitter_id.append(i)\n",
        "\n",
        "    for item in twitter_id[:]:\n",
        "      if 'adamsandreese' in item:\n",
        "          twitter_id.remove(item)\n",
        "\n",
        "    # check for empty list\n",
        "    if not twitter_id:\n",
        "      filtered_list.append('none')\n",
        "    else:\n",
        "      filtered_list.append(twitter_id)\n",
        "  except Exception as error:\n",
        "    print(\"An exception occured:\", error)\n",
        "    break\n",
        "\n",
        "print(filtered_list)\n",
        "# Add the results to the dataframe\n",
        "merged = list(zip_longest(df[input_column], filtered_list, fillvalue = None))\n",
        "df = pd.DataFrame(merged, columns=['lawyer name', 'twitter id'])\n",
        "\n",
        "# Write the updated dataframe back to the Excel file\n",
        "df.to_csv(file_path, index = False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y2m0Lw-RENwl",
        "outputId": "bbad277f-212f-46d2-8393-d93fa33981f3"
      },
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\"['chuckadamsar']\", 'none', \"['richieaguilar88']\", 'none', 'none', \"['drlukeallen', 'coachacallen']\", \"['timanzenberger']\", \"['wtmatkinson', 'WTMAtkinson']\", \"['la_baio']\", \"['randyebarnett']\", 'none', 'none', 'none', 'none', \"['drjennybee']\", 'none', \"['dbernstein', 'davidlbernstein']\", \"['MarkBerson1']\", 'none', 'none', 'none', 'none', 'none', 'none', \"['cbbonner']\", 'none', 'none', 'none', 'none', 'none', 'none', \"['mattbruenig']\", \"['bennybriggs1']\", 'none', 'none', 'none', \"['taylorbrooks']\", 'none', 'none', \"['seanbuckley', 'attorneybuckley?lang=de']\", 'none', 'none', \"['bradleybyrne']\", 'none', 'none', \"['campbelladam79']\", 'none', 'none', 'none', \"['shadylawrence']\", 'none', 'none', \"['tnlastcall']\", 'none', 'none', \"['adamcopes', 'matt_copeland1']\", 'none', 'none', 'none', 'none', 'none', \"['attorneyjeremy1']\", 'none', 'none', 'none', 'none', \"['adzjt15', 'dart_adams']\", \"['JDavisOfficial']\", \"['superdavis78']\", 'none', \"['ginadtucker']\", 'none', 'none', 'none', \"['domianojl']\", 'none', 'none', 'none', 'none', \"['APD849']\", 'none', 'none', 'none', 'none', 'none', \"['ifcapdiesidie']\", 'none', 'none', 'none', \"['adamferrara']\", 'none', 'none', \"['andrufreeman', 'andrewfreemanpr?lang=bn']\", 'none', 'none', \"['reecegaines1', 'edgainesiii']\", 'none', 'none', 'none', 'none', \"['robgill_epic']\", \"['javgonz']\", \"['roscoegreeniii']\", \"['theadamgregory']\", \"['ProfGrewal']\", 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', \"['lmeltzerhenry']\", \"['randyhetrick']\", 'none', 'none', \"['sethpowerhood']\", \"['johnhooksMT']\", 'none', 'none', \"['azjackson85']\", \"['adamjohnsonchi']\", \"['davidjohnson31']\", 'none', 'none', \"['J_SamJones']\", \"['chris_d_joseph']\", 'none', 'none', \"['kearnsdavis']\", 'none', 'none', 'none', 'none', 'none', \"['reeses']\", \"['rosscoulthart']\", 'none', 'none', 'none', \"['aroselli89']\", \"['NewsLambert']\", \"['balampley79']\", 'none', \"['leduff_taylor']\", \"['rabbijosh']\", \"['oneadamreese']\", 'none', 'none', 'none', 'none', 'none', 'none', \"['robwestiii']\", 'none', 'none', \"['criticalmassey']\", 'none', 'none', 'none', \"['kokomo6253']\", 'none', 'none', 'none', 'none', 'none', \"['culturedmodesty']\", 'none', 'none', ['actualbenmiller', 'Adam_CV_Miller'], ['co_mill'], 'none', 'none', ['RepAdamMorgan'], ['lmorrowentlaw'], ['myersmargaret'], ['robert_nolan'], 'none', 'none', 'none', 'none', ['owenmryan'], 'none', 'none', 'none', 'none', ['lucianpera'], 'none', 'none', 'none', ['tnlastcall'], 'none', 'none', ['apopey'], 'none', 'none', ['jjpringlesc'], ['rwpritchett', 'rwpritchett'], ['brianpugh2'], 'none', 'none', ['kyleadamsrva'], ['Rahll'], ['samrichardswebb', 'sociosammy'], ['ajrichar'], ['ajrichar'], 'none', ['arrroberts'], ['elliottjmr'], 'none', 'none', 'none', ['jaymross52', 'Adam_M_Ross'], 'none', 'none', ['rowebotz'], ['AdamERussell'], 'none', ['adamsanderslive'], 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', ['bill_shea19'], 'none', ['benshelton'], 'none', 'none', 'none', 'none', 'none', ['CaitlinSmithTX'], 'none', 'none', 'none', ['adamstern'], ['daviehollywoody', 'daviehollywoody'], 'none', ['AdamStewart', 'AdamStewart'], ['oneadamreese'], 'none', 'none', 'none', 'none', 'none', ['1taketaylor'], 'none', 'none', 'none', ['davidtoney7'], ['adamscrabble', 'adamscrabble'], ['allyce_trapp'], 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', ['raywardutah'], 'none', 'none', 'none', ['adamlaw50'], 'none', 'none', 'none', 'none', 'none', ['andrewwilsonaw'], ['davewolfusa'], ['maiawoodhouse'], 'none', ['William34869306'], 'none', 'none', 'none', 'none', 'none']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lawyerurl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k1pVQ25a5Fui",
        "outputId": "0eaf45bd-d957-4231-acec-22502f90b07c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['https://twitter.com/chuckadamsar',\n",
              " 'https://twitter.com/adamsandreese/status/1755574837865570464',\n",
              " 'https://twitter.com/adam_cannon?lang=en',\n",
              " 'https://twitter.com/drlukeallen?lang=en',\n",
              " 'https://twitter.com/timanzenberger?lang=en',\n",
              " 'https://twitter.com/WTMAtkinson',\n",
              " 'https://twitter.com/la_baio?lang=en',\n",
              " 'https://twitter.com/adamsandreese/status/1755574837865570464',\n",
              " 'https://twitter.com/dbernstein?lang=en',\n",
              " 'https://twitter.com/davidlbernstein?lang=en',\n",
              " 'https://twitter.com/cbbonner?lang=en',\n",
              " 'https://twitter.com/adamsandreese/status/948961860904202246?lang=en',\n",
              " 'https://twitter.com/adamsandreese/status/1458868876113059849',\n",
              " 'https://twitter.com/seanbuckley?lang=en',\n",
              " 'https://twitter.com/AttorneyBuckley',\n",
              " 'https://twitter.com/BradleyByrne',\n",
              " 'https://twitter.com/Robertc1970',\n",
              " 'https://twitter.com/paulreindlsd?lang=en',\n",
              " 'https://twitter.com/tnlastcall?lang=en',\n",
              " 'https://twitter.com/RoofCoffeeShop/status/1683885295228293121',\n",
              " 'https://twitter.com/jdavisofficial?lang=en',\n",
              " 'https://twitter.com/ginadtucker?lang=en',\n",
              " 'https://twitter.com/dani_dougs?lang=en',\n",
              " 'https://twitter.com/adamsandreese/status/161868628227137536',\n",
              " 'https://twitter.com/adamduerson?lang=en',\n",
              " 'https://twitter.com/achrisevans/status/749969917055799296?lang=en',\n",
              " 'https://twitter.com/adamsandreese/status/1762604363405480131',\n",
              " 'https://twitter.com/AndruFreeman']"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import xlsxwriter\n",
        "import xlrd\n",
        "from collections import OrderedDict\n",
        "import tweepy\n",
        "import datetime\n",
        "import time\n",
        "\n",
        "# API Auth ë°›ê¸°\n",
        "client = tweepy.Client(\n",
        "    bearer_token = \"AAAAAAAAAAAAAAAAAAAAABF0rgEAAAAA6fb3wEWef68E5ibNkS3NYtmRM9I%3D9ehXrnUMBnYNCmuQUdGdTbvoV8saXM9x3IqzFV36GS1IRRSeh2\",\n",
        "    consumer_key= \"OB3FBQsfgBtLxsmY8zf1McMLV\",\n",
        "    consumer_secret= \"Eg8Zwg7MsnFWyNLY92iNKJ74tylqjnWT2VsdepmpOn6oo71VaH\",\n",
        "    access_token= \"1616524542880481285-lo2Dl0Ke9ImLRd1zdEUvQT9i8vfCQS\",\n",
        "    access_token_secret= \"olX7JuenBPyE93732LG29QUCWSCmZabrgfZ9gy818IGzf\",\n",
        "    wait_on_rate_limit=True\n",
        ")\n",
        "\n",
        "auth = tweepy.OAuthHandler(\"OB3FBQsfgBtLxsmY8zf1McMLV\", \"Eg8Zwg7MsnFWyNLY92iNKJ74tylqjnWT2VsdepmpOn6oo71VaH\")\n",
        "auth.set_access_token(\"1616524542880481285-lo2Dl0Ke9ImLRd1zdEUvQT9i8vfCQS\",\n",
        "                      \"olX7JuenBPyE93732LG29QUCWSCmZabrgfZ9gy818IGzf\")\n",
        "api = tweepy.API(auth)\n",
        "\n",
        "# íŠ¸ìœ„í„° ê³„ì • Description ë°›ì•„ë‚´ëŠ” ì½”ë“œ\n",
        "for i in twitter_id:\n",
        "  response = client.get_user(username = i, user_fields = [\"description\", \"public_metrics\", \"name\", \"url\"])\n",
        "  user = response.data\n",
        "  try:\n",
        "    values = {\"user_id\": user.id, \"username\": user.username, \"description\": user.description, \"name\": user.name, \"url\": user.url}\n",
        "    values.update(user.public_metrics)\n",
        "    ser = pd.Series(values)\n",
        "    description = ser[2]\n",
        "    name = ser[3]\n",
        "    url = ser[4]\n",
        "    print(\"{} -\".format(name), \"{}:\".format(i), description, unshorten_url(url), \"\\n\")\n",
        "  except Exception as error:\n",
        "    print(error)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0NozYfu2vEpP",
        "outputId": "f5d65da9-725b-4d4a-d29b-36ddb7c88c03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Charles P. Adams, Jr - chuckadamsar: Husband, Father, Grandfather, Georgetown Grad and Hoya fan. Former Managing Partner at Adams and Reese LLP. Sharing miscellaneous Observations. https://www.adamsandreese.com/ \n",
            "\n",
            "Adam Cannon - adam_cannon: Director of Legal @TheSun and a photographer \n",
            "\n",
            "#followme on Insta: https://t.co/mPQeKqHWRf https://linktr.ee/Thetravellingbrief \n",
            "\n",
            "Luke Allen - drlukeallen: Health systems policy & practice. Fellow @LSHTM | Oxford GP | Consultant @WHO & @WorldBank | Board @BJGPjournal | Prev Harvard/MIT. Fighting social injustice https://drlukeallen.mystrikingly.com/ \n",
            "\n",
            "Tim Anzenberger - timanzenberger: Partner at Adams and Reese LLP: Bankruptcy, Commercial Litigation, and Appellate Practice. Mississippi/North Carolina. None \n",
            "\n",
            "William Atkinson - WTMAtkinson: Assistant Editor @ConHome\n",
            "Tory Leninist and voice of yoof \n",
            "'A total Tory BNOC' - @Tatlermagazine\n",
            "william@conservativehome.com None \n",
            "\n",
            "Lauren Baio - la_baio: Florida and Washington, D.C. licensed attorney with a passion for ocean conservation. None \n",
            "\n",
            "David S. Bernstein - dbernstein: Mitt Romney once tried to wager $10,000 that I got something wrong. Freelance journalist, covering local, state, & national politics and policy. https://davidsbernstein.substack.com/ \n",
            "\n",
            "David Bernstein - davidlbernstein: Founder of Jewish Institute for Liberal Values | Book: Woke Antisemitism - How a Progressive Ideology Harms Jews | Buy on Amazon: https://t.co/NiYmOlFNLH https://jilv.org/ \n",
            "\n",
            "C. Britton Bonner - cbbonner:  https://www.adamsandreese.com/ \n",
            "\n",
            "Sean Buckley - seanbuckley: Business attorney in #Dallas #FortWorth. I post about advertising, digital marketing, beer, wine, law, privacy, urbanism, and development. https://www.dykema.com/people/sean-m-buckley.html \n",
            "\n",
            "Sean Buckley âš–ï¸ğŸŒŠâœğŸ¿ - AttorneyBuckley: Husband| #Author; Oâ€™Connorâ€™s Federal Criminal Rules & Codes 2024-2025. ~Defense Attorney âš–ï¸War Eagle ğŸˆ#BuckleyCriminalDefenseAttorney #WritingCommunity https://www.seanbuckleylaw.com/ \n",
            "\n",
            "Bradley Byrne - BradleyByrne: Dad, Grandfather, and proud Alabamian fighting for conservative values. None \n",
            "\n",
            "Rob Campbell - Robertc1970: Positive pessimist. Also a Forest fan. Probably connected. Ex-Cynic, Wieden+Kennedy & R/GA. Now at Colenso, Weigel/Campbell & Metallica. https://robcampbell.co/ \n",
            "\n",
            "Paul Reindl - paulreindlsd: Executive Producer for @BenAndWoods https://www.audacy.com/973thefansd/authors/paul-reindl \n",
            "\n",
            "Will Cheek - tnlastcall: Will Cheek is the go-to source for liquor licensing in Tennessee and blogs about liquor at https://t.co/BX0n6OguNT None \n",
            "\n",
            "RoofersCoffeeShopÂ® - RoofCoffeeShop: We are a community of #roofing professionals that share ideas, tell stories, research, sell stuff and find help. We are Where The Roofing Industry Meets! https://www.rooferscoffeeshop.com/ \n",
            "\n",
            "Jonathan Davis - jdavisofficial: https://t.co/qQWUu7ib2c https://www.jonathandavis.com/ \n",
            "\n",
            "Gina Tucker - ginadtucker: plant-based food marketer None \n",
            "\n",
            "Danielle Douglas - dani_dougs: Law Student, University of Calgary. Program Coordinator, Pro Bono Students Canada @pbsccalgary None \n",
            "\n",
            "Adam Duerson - adamduerson: Editor-In-Chief, @FOS. Formerly: Exec Editor, @SInow. I got â€œsteamrolleredâ€ changed to â€œsteamrolledâ€ in the SI style guide âœŠ  adam.duerson@frontofficesports.com https://frontofficesports.com/ \n",
            "\n",
            "Chris Evans - achrisevans: Host of The Virgin Radio Breakfast Show with Sky, creator of CarFest, custodian of 500 Words. But mostly punching way above his weight in the marriage dept. https://virginradio.co.uk/shows/the-chris-evans-breakfast-show \n",
            "\n",
            "Andrew Freeman - AndruFreeman: Official Twitter for #AndrewFreeman Frontman for #LastInLine. Former guitarist for #Offspring - Former singer #LynchMob #DevilsHand https://www.andrewfreemanmusic.com/ \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Possible word to check whether the user is a Lawyer: \"legal\", \"LLP\", \"company name\", \"attorney\", \"pro bono\", \"probono\","
      ],
      "metadata": {
        "id": "RehRqe1_4mVL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ì“°ë ˆê¸°í†µ\n",
        "\n",
        "# Step 2\n",
        "\n",
        "# ì—‘ì…€íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°\n",
        "file_path = \"/content/drive/MyDrive/Lawyers/Accounts/AdamandReese/Adam and Reese LLP Twitter.csv\"\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "input_column = df.columns[1]\n",
        "output_column = df.columns[2]\n",
        "# print(namelist)\n",
        "\n",
        "# ë¦¬ìŠ¤íŠ¸ì•ˆì— ë³€í˜¸ì‚¬ ì´ë¦„ë³„ë¡œ ê²€ìƒ‰í•˜ì—¬ íŠ¸ìœ„í„° ê³„ì • ì°¾ê¸°\n",
        "for i in input_column[:]:\n",
        "  try:\n",
        "    searchs = '{} {} \"Twitter\"'.format(company, i)\n",
        "    results = s(searchs, sleep_interval = 1, num_results = 1)\n",
        "    for r in results:\n",
        "      if r.startswith(twitterurl):\n",
        "        lawyerurl.append(r)\n",
        "    input_column.remove(i)\n",
        "  except Exception as error:\n",
        "    print(\"An exception occured:\", error)\n",
        "    break\n",
        "\n",
        "print(lawyerurl)\n",
        "\n",
        "# Assuming the input is in the first column (A) and we want to write the output to the second column (B)\n",
        "# Modify this as per your specific requirements\n",
        "input_column = df.columns[0]  # or df.columns[0] if you want to use the first column dynamically\n",
        "output_column = df.columns[1]  # or df.columns[1] if you want to use the second column dynamically\n",
        "\n",
        "# Process each input and store the result in a new list\n",
        "outputs = []\n",
        "for input_value in df[input_column]:\n",
        "    # Replace the following line with your actual processing logic\n",
        "    output_value = process_input(input_value)  # Example function to process input\n",
        "    outputs.append(output_value)\n",
        "\n",
        "# Add the results to the dataframe\n",
        "df[output_column] = outputs\n",
        "\n",
        "# Write the updated dataframe back to the Excel file\n",
        "df.to_csv(file_path, index=False)\n",
        "\n",
        "\n",
        "\n",
        "#__________________________________________________________________________ Step 2\n",
        "\n",
        "# ì—‘ì…€íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°\n",
        "file_path = \"/content/drive/MyDrive/Lawyers/Accounts/AdamandReese/Adam and Reese LLP Twitter.csv\"\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "namelist = newdf['lawyer name'].tolist()\n",
        "# print(namelist)\n",
        "\n",
        "# ë¦¬ìŠ¤íŠ¸ì•ˆì— ë³€í˜¸ì‚¬ ì´ë¦„ë³„ë¡œ ê²€ìƒ‰í•˜ì—¬ íŠ¸ìœ„í„° ê³„ì • ì°¾ê¸°\n",
        "for i in namelist[:]:\n",
        "  try:\n",
        "    searchs = '{} {} \"Twitter\"'.format(company, i)\n",
        "    results = s(searchs, sleep_interval = 1, num_results = 1)\n",
        "    for r in results:\n",
        "      if r.startswith(twitterurl):\n",
        "        lawyerurl.append(r)\n",
        "    namelist.remove(i)\n",
        "  except Exception as error:\n",
        "    print(\"An exception occured:\", error)\n",
        "    break\n",
        "\n",
        "print(lawyerurl)\n",
        "\n",
        "# # íšŒì‚¬ ê³µì‹ íŠ¸ìœ„í„° ê³„ì • ë¦¬ìŠ¤íŠ¸ì—ì„œ ëª¨ë‘ ì œê±°\n",
        "# url_to_remove = 'https://twitter.com/adamsandreese?lang=en'\n",
        "\n",
        "# if url_to_remove in lawyerurl:\n",
        "#   lawyerurl.remove(url_to_remove)\n",
        "\n",
        "# try:\n",
        "#   lawyerurl.remove(url_to_remove)\n",
        "# except ValueError:\n",
        "#   print(f\"The URL was not found in the list.\")\n",
        "\n",
        "# print(lawyerurl)\n",
        "\n",
        "# íšŒì‚¬ ê³µì‹ íŠ¸ìœ„í„° ê³„ì • ë¦¬ìŠ¤íŠ¸ì—ì„œ ëª¨ë‘ ì œê±°\n",
        "url_to_remove = 'https://twitter.com/adamsandreese?lang=en'\n",
        "\n",
        "lawyerurl = [item for item in lawyerurl if item != 'https://twitter.com/adamsandreese?lang=en']\n",
        "\n",
        "print(lawyerurl)\n",
        "\n",
        "# íŠ¸ìœ„í„° ê²°ê³¼ ë° ë‚¨ì€ ë³€í˜¸ì‚¬ ë”°ë¡œ ì—‘ì…€ íŒŒì¼ë¡œ ì €ì¥\n",
        "leftover = pd.DataFrame(namelist)\n",
        "lawyertwitterurl = pd.DataFrame(lawyerurl)\n",
        "\n",
        "# íšŒì‚¬ì— ë§ì¶° ê²½ë¡œ ë³€ê²½ í•  ê²ƒ\n",
        "leftover.to_csv(\"/content/drive/MyDrive/Lawyers/Accounts/AdamandReese/leftover{}.csv\".format(number_count))\n",
        "lawyertwitterurl.to_csv(\"/content/drive/MyDrive/Lawyers/Accounts/AdamandReese/TwitterUrl{}.csv\".format(number_count))\n",
        "\n",
        "number_count += 1\n",
        "\n",
        "# ì—‘ì…€íŒŒì¼ë¡œ ì €ì¥í•œ íŠ¸ìœ„í„° URL ë¶ˆëŸ¬ì˜¤ê¸°\n",
        "\n",
        "twitterurlpath = \"/content/drive/MyDrive/Lawyers/Accounts/AdamsandReese/ARTwitterUrl.csv\"\n",
        "df = pd.read_csv(twitterurlpath)\n",
        "columns = [\"0\"]\n",
        "newdf = df[columns]\n",
        "\n",
        "twitterurl = newdf['0'].tolist()\n",
        "twitterurl\n",
        "\n",
        "# ì—‘ì…€íŒŒì¼ë¡œ ì €ì¥í•œ ë‚¨ì€ ë³€í˜¸ì‚¬ë“¤ ë¶ˆëŸ¬ì˜¤ê¸°\n",
        "\n",
        "leftoverpath = \"/content/drive/MyDrive/Lawyers/Accounts/AdamsandReese/ARleftover.csv\"\n",
        "df = pd.read_csv(leftoverpath)\n",
        "columns = [\"0\"]\n",
        "newdf = df[columns]\n",
        "\n",
        "leftover = newdf['0'].tolist()\n",
        "leftover\n",
        "\n",
        "# ì—‘ì…€íŒŒì¼ì— ì €ì¥í•œ ë‚¨ì€ ë³€í˜¸ì‚¬ë“¤ ë¶ˆëŸ¬ì„œ ë‹¤ì‹œ íŠ¸ìœ„í„° ê³„ì • ì°¾ì„ ë•Œ ëŒë¦´ ìˆ˜ ìˆëŠ” ì½”ë“œ\n",
        "import pandas as pd\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from googlesearch import search as s\n",
        "import re\n",
        "\n",
        "working = []\n",
        "company = \"Adam and Reese LLP\"\n",
        "twitterurl = \"https://twitter.com/\"\n",
        "\n",
        "for i in leftover[:]:\n",
        "  try:\n",
        "    searchs = '{} {} \"Twitter\"'.format(company, i)\n",
        "    results = s(searchs, sleep_interval = 1, num_results = 1)\n",
        "    for r in results:\n",
        "      if r.startswith(twitterurl):\n",
        "        working.append(r)\n",
        "    leftover.remove(i)\n",
        "  except Exception as error:\n",
        "    print(\"An exception occured:\", error)\n",
        "\n",
        "# íšŒì‚¬ ê³µì‹ íŠ¸ìœ„í„° ê³„ì • ë¦¬ìŠ¤íŠ¸ì—ì„œ ëª¨ë‘ ì œê±°\n",
        "working = [item for item in working if item != 'https://twitter.com/adamsandreese?lang=en']\n",
        "\n",
        "print(working)\n",
        "\n",
        "\n",
        "# íŠ¸ìœ„í„° ë§í¬ì—ì„œ íŠ¸ìœ„í„° ID ì¶”ì¶œ\n",
        "twitter_id = []\n",
        "pattern = r'\\d{19}'\n",
        "patterns = r'\\d{18}'\n",
        "for i in lawyerurl:\n",
        "  i = i.replace(\"https://twitter.com/\", \"\")\n",
        "  i = i.replace(\"?lang=en\",\"\")\n",
        "  i = i.replace(\"/status/\",\"\")\n",
        "  i = re.sub(pattern, \"\", i)\n",
        "  i = re.sub(patterns, \"\", i)\n",
        "  twitter_id.append(i)\n",
        "\n",
        "print(twitter_id)\n",
        "\n",
        "\n",
        "# íšŒì‚¬ ê³µì‹ íŠ¸ìœ„í„° ê³„ì • ë¦¬ìŠ¤íŠ¸ì—ì„œ ëª¨ë‘ ì œê±°\n",
        "twitter_id = [item for item in twitter_id if item != 'adamsandreese']\n",
        "\n",
        "print(twitter_id)"
      ],
      "metadata": {
        "id": "buf-0uSRwyJN",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}