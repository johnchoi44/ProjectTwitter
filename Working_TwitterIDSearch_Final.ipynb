{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO9xqW+oTFqu3OtoMk91GZE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/johnchoi44/ProjectTwitter/blob/main/Working_TwitterIDSearch_Final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nUl5CEFsqFc-",
        "outputId": "18e00778-0b7a-48ce-b64e-884ac5f9bacb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "# 구글 드라이브 연결\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 필요 라이브러리 설치\n",
        "!pip install googlesearch-python\n",
        "!pip install xlsxwriter"
      ],
      "metadata": {
        "id": "KQAIqh65qIez",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9bb6c4b-ee85-450e-d085-8a23f2718eb8",
        "collapsed": true
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting googlesearch-python\n",
            "  Downloading googlesearch_python-1.2.4-py3-none-any.whl (4.5 kB)\n",
            "Requirement already satisfied: beautifulsoup4>=4.9 in /usr/local/lib/python3.10/dist-packages (from googlesearch-python) (4.12.3)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from googlesearch-python) (2.31.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4>=4.9->googlesearch-python) (2.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->googlesearch-python) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->googlesearch-python) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->googlesearch-python) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->googlesearch-python) (2024.7.4)\n",
            "Installing collected packages: googlesearch-python\n",
            "Successfully installed googlesearch-python-1.2.4\n",
            "Collecting xlsxwriter\n",
            "  Downloading XlsxWriter-3.2.0-py3-none-any.whl (159 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m159.9/159.9 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xlsxwriter\n",
            "Successfully installed xlsxwriter-3.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 라이브러리 import\n",
        "import pandas as pd\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from googlesearch import search as s\n",
        "import re\n",
        "from itertools import zip_longest\n",
        "import math\n",
        "import os"
      ],
      "metadata": {
        "id": "a_6gfGK-qMHR"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Code to get full URL\n",
        "import requests\n",
        "\n",
        "def unshorten_url(short_url):\n",
        "  if short_url == None:\n",
        "    return None\n",
        "  else:\n",
        "    try:\n",
        "      response = requests.get(short_url, allow_redirects=True)\n",
        "      return response.url\n",
        "    except:\n",
        "      return None"
      ],
      "metadata": {
        "id": "bLd4x9nJ8jg-"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "number_count = 1\n",
        "# 검색용 variable 설정\n",
        "twitterurl = \"https://twitter.com/\"\n",
        "company = \"ArentFox Schiff\" # 회사에 맞춰 변경"
      ],
      "metadata": {
        "id": "HFHUIiacsGfA"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# search function defined\n",
        "def search_input(input_value, company):\n",
        "  twitterurl = \"https://twitter.com/\"\n",
        "  lawyerurl = []\n",
        "  searchs = '{} {} Twitter'.format(company, input_value)\n",
        "  results = s(searchs, sleep_interval = 1, num_results = 1)\n",
        "  for r in results:\n",
        "    if r.startswith(twitterurl):\n",
        "      lawyerurl.append(r.lower())\n",
        "  return lawyerurl"
      ],
      "metadata": {
        "id": "Tpcn96eGt0DD"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1 (초반에 한번만 execute)\n",
        "\n",
        "# 변호사 이름 엑셀파일에서 불러와서 리스트로 만들기\n",
        "lawyerurl = []\n",
        "path = \"/content/drive/MyDrive/Lawyers/Lawyers_Twitter_Turnover/Schiff Hardin//Schiff Hardin.xlsx\" # 경로 회사에 맞춰 변경\n",
        "df = pd.read_excel(path) # read_csv - if it is a csv file\n",
        "columns = [\"Lawyer Name\"]\n",
        "newdf = df[columns]\n",
        "\n",
        "folder = \"/content/drive/MyDrive/Lawyers/Accounts/Schiff Hardin\"\n",
        "\n",
        "os.mkdir(folder)\n",
        "csv_file_path = \"/content/drive/MyDrive/Lawyers/Accounts/Schiff Hardin/{} Twitter.csv\".format(company)\n",
        "newdf.to_csv(csv_file_path, index=False)"
      ],
      "metadata": {
        "id": "XzLOuMwgu9t8"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2 (한번 execute 이후 Step 3 execute)\n",
        "\n",
        "# 엑셀파일 불러오기\n",
        "file_path = csv_file_path\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "input_column = df.columns[0]\n",
        "\n",
        "outputs = []\n",
        "twitter_link = []\n",
        "pattern = r'\\d{19}'\n",
        "patterns = r'\\d{18}'\n",
        "for input_value in df[input_column]:\n",
        "  twitter_id = []\n",
        "  try:\n",
        "    output_value = search_input(input_value, company)\n",
        "\n",
        "    for i in output_value:\n",
        "      i = i.replace(\"https://twitter.com/\", \"\")\n",
        "      i = i.replace(\"/status/\",\"\")\n",
        "      i = re.sub(r\"\\?lang=[a-zA-Z]{2}\", \"\", i)\n",
        "      i = re.sub(pattern, \"\", i)\n",
        "      i = re.sub(patterns, \"\", i)\n",
        "      twitter_id.append(i)\n",
        "\n",
        "    for item in twitter_id[:]: # find company's official twitter account and put it here\n",
        "      if 'schiff_hardin' in item:\n",
        "        twitter_id.remove(item)\n",
        "      elif 'arentfoxschiff' in item:\n",
        "        twitter_id.remove(item)\n",
        "      elif 'arentfox' in item:\n",
        "        twitter_id.remove(item)\n",
        "\n",
        "    twitter_id = list(set(twitter_id))\n",
        "\n",
        "    # check for empty list\n",
        "    if not twitter_id:\n",
        "      outputs.append('none')\n",
        "    else:\n",
        "      outputs.append(twitter_id)\n",
        "  except Exception as error:\n",
        "    print(\"An exception occured:\", error)\n",
        "    break\n",
        "\n",
        "print(outputs)\n",
        "# Add the results to the dataframe\n",
        "merged = list(zip_longest(df[input_column], outputs, fillvalue = None))\n",
        "df = pd.DataFrame(merged, columns=['lawyer name', 'twitter id'])\n",
        "\n",
        "# Write the updated dataframe back to the Excel file\n",
        "df.to_csv(file_path, index = False)"
      ],
      "metadata": {
        "id": "OQZr0lUTtS-H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7789d6b0-8529-4cd0-b4bf-719aeaa1174b"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "An exception occured: 429 Client Error: Too Many Requests for url: https://www.google.com/sorry/index?continue=https://www.google.com/search%3Fq%3DArentFox%252BSchiff%252B%25250AJoseph%252BP.%252BCrimmins%25250A%252BTwitter%26num%3D3%26hl%3Den%26start%3D0%26safe%3Dactive&hl=en&q=EgQiU91yGL_P2LQGIjA_tTWgxqhr-tj2YbDWYNNwh4KbvhnR_C_wQs2On9poSTTvVV1BIFanTGA5ec0kNdwyAXJaAUM\n",
            "['none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', ['thenlj'], 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', ['2020andrewbanks', 'andrewbanks'], 'none', 'none', ['sfbart'], ['andy_baskin'], 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', ['richard_berman', 'berman_rick'], 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', ['nazaninboniadi'], 'none', 'none', ['matthewbowden'], 'none', 'none', 'none', 'none', 'none', ['tombrennan27'], 'none', 'none', 'none', 'none', ['garydonbrophy'], 'none', ['lbrownhealthlaw'], 'none', 'none', 'none', 'none', ['rpeterbusch', 'peterbuschtv'], 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', ['katiephang'], ['colombialawbiz/statuses/'], 'none', 'none', 'none', 'none', ['writercrafter'], 'none', 'none', 'none', 'none', 'none', 'none', ['adamschiff'], 'none', 'none', ['cdasay'], 'none', 'none', ['briantylercohen'], ['aricohn', 'sarah_cohn'], 'none', 'none', ['michellec1982jd'], ['imbrettcooper'], 'none', 'none', 'none', 'none', 'none', 'none', 'none']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outputs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        },
        "id": "gzBpTR0kiDNm",
        "outputId": "cdf080e9-edca-4275-e9ac-c4704d086344"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'outputs' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-0dde94a30ad7>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'outputs' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3\n",
        "\n",
        "# 엑셀파일 불러오기\n",
        "csv_file_path = \"/content/drive/MyDrive/Lawyers/Accounts/Schiff Hardin/Schiff Hardin Twitter.csv\"\n",
        "file_path = csv_file_path\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "input_column = df.columns[0]\n",
        "output_column = df.columns[1]\n",
        "\n",
        "# get the count of the output column\n",
        "output_list = df[output_column]\n",
        "filtered_list = [item for item in output_list if not (isinstance(item, float) and math.isnan(item))]\n",
        "count = len(filtered_list)\n",
        "\n",
        "pattern = r'\\d{19}'\n",
        "patterns = r'\\d{18}'\n",
        "for input_value in df[input_column][count:]:\n",
        "  twitter_id = []\n",
        "  try:\n",
        "    output_value = search_input(input_value, company)\n",
        "\n",
        "    for i in output_value:\n",
        "      i = i.replace(\"https://twitter.com/\", \"\")\n",
        "      i = i.replace(\"/status/\",\"\")\n",
        "      i = re.sub(r\"\\?lang=[a-zA-Z]{2}\", \"\", i)\n",
        "      i = re.sub(pattern, \"\", i)\n",
        "      i = re.sub(patterns, \"\", i)\n",
        "      twitter_id.append(i)\n",
        "\n",
        "    for item in twitter_id[:]: # find company's official twitter account and put it here\n",
        "      if 'schiff_hardin' in item:\n",
        "        twitter_id.remove(item)\n",
        "      elif 'arentfox' in item:\n",
        "        twitter_id.remove(item)\n",
        "      elif 'arentfoxschiff' in item:\n",
        "        twitter_id.remove(item)\n",
        "\n",
        "    twitter_id = list(set(twitter_id))\n",
        "\n",
        "    # check for empty list\n",
        "    if not twitter_id:\n",
        "      filtered_list.append('none')\n",
        "    else:\n",
        "      filtered_list.append(twitter_id)\n",
        "  except Exception as error:\n",
        "    print(\"An exception occured:\", error)\n",
        "    break\n",
        "\n",
        "print(filtered_list)\n",
        "# Add the results to the dataframe\n",
        "merged = list(zip_longest(df[input_column], filtered_list, fillvalue = None))\n",
        "df = pd.DataFrame(merged, columns=['lawyer name', 'twitter id'])\n",
        "\n",
        "# Write the updated dataframe back to the Excel file\n",
        "df.to_csv(file_path, index = False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y2m0Lw-RENwl",
        "outputId": "f787e3ed-d87f-48f8-ea80-24a0154073fa"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', \"['thenlj']\", 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', \"['2020andrewbanks', 'andrewbanks']\", 'none', 'none', \"['sfbart']\", \"['andy_baskin']\", 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', \"['richard_berman', 'berman_rick']\", 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', \"['nazaninboniadi']\", 'none', 'none', \"['matthewbowden']\", 'none', 'none', 'none', 'none', 'none', \"['tombrennan27']\", 'none', 'none', 'none', 'none', \"['garydonbrophy']\", 'none', \"['lbrownhealthlaw']\", 'none', 'none', 'none', 'none', \"['rpeterbusch', 'peterbuschtv']\", 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', \"['katiephang']\", \"['colombialawbiz/statuses/']\", 'none', 'none', 'none', 'none', \"['writercrafter']\", 'none', 'none', 'none', 'none', 'none', 'none', \"['adamschiff']\", 'none', 'none', \"['cdasay']\", 'none', 'none', \"['briantylercohen']\", \"['aricohn', 'sarah_cohn']\", 'none', 'none', \"['michellec1982jd']\", \"['imbrettcooper']\", 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', \"['michaelcryan']\", 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', \"['itslitrllymine']\", 'none', 'none', \"['pmdeese']\", 'none', 'none', 'none', 'none', \"['chrisdibii']\", 'none', \"['mpdimino', 'mrdimino']\", 'none', 'none', 'none', \"['adamschiff']\", 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', \"['adoobs']\", \"['davedauthor']\", 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', \"['carolinemturner']\", 'none', 'none', 'none', 'none', \"['brian_farkas']\", 'none', 'none', \"['patrickhfeeney']\", 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', \"['ricardofischer']\", 'none', \"['markfisherfocus']\", 'none', 'none', \"['dougflahaut']\", 'none', 'none', 'none', \"['iamryanfoley']\", 'none', 'none', 'none', \"['chefjeremyfox', 'jeremydanielfox']\", 'none', \"['lexisnexis']\", 'none', 'none', 'none', 'none', \"['fresnostatelax']\", 'none', 'none', 'none', 'none', \"['electmikegarcia', 'repmikegarcia']\", 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', \"['epetergiles']\", 'none', \"['rudygiuliani']\", 'none', 'none', 'none', 'none', \"['robreiner']\", 'none', \"['mike_gordon', 'mikegordonobs']\", 'none', 'none', 'none', 'none', 'none', \"['secgranholm']\", \"['greenbergcap']\", 'none', 'none', 'none', \"['griffao']\", 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', \"['jayharrington3']\", \"['kristenhartesq']\", 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', \"['jeff_jordan']\", 'none', 'none', \"['bachlaw']\", 'none', 'none', 'none', 'none', 'none', 'none', 'none', \"['michaeljkellyjr']\", \"['jeffreyckennedy']\", 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', \"['awesomekling', 'avocadojackson']\", 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', \"['patricklaib4t']\", 'none', 'none', 'none', 'none', 'none', \"['benjaminleese']\", 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', \"['dllorent']\", 'none', 'none', 'none', 'none', 'none', \"['aaronsirisg']\", 'none', 'none', \"['thenlj']\", 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', \"['annagmandel']\", 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', \"['roberto_m_jr']\", 'none', 'none', 'none', 'none', \"['zeta_5566']\", 'none', 'none', 'none', 'none', 'none', 'none', \"['emilywthr', 'claremaguire']\", 'none', 'none', \"['drewjmclaughlin']\", 'none', 'none', 'none', \"['mallorymcmahon']\", 'none', 'none', 'none', 'none', 'none', \"['miss_mercedes4', 'sawyermerritt']\", \"['merkle']\", 'none', 'none', \"['shipdontdie', 'theduiguyplus']\", 'none', 'none', 'none', 'none', 'none', 'none', \"['_jeffmitchell_', 'fatherofben']\", 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', \"['jamestmurphy_']\", \"['abigailmyers22']\", 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', \"['kristin_niver']\", \"['matthewnolaan', 'md_nolan']\", \"['davidjnoonan', 'davenoonancfmeu']\", 'none', \"['chrisanorton16']\", 'none', 'none', 'none', 'none', 'none', \"['ucheora']\", 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', \"['anthonypeluso23']\", 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', \"['repadamschiff']\", 'none', 'none', 'none', 'none', 'none', 'none', \"['bookeboy', 'caveofprogram']\", 'none', \"['repmikequigley']\", 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', \"['mcadoogordon']\", 'none', \"['owen_roe']\", 'none', 'none', 'none', 'none', 'none', \"['ericaislegit']\", 'none', 'none', 'none', \"['andrewross11']\", \"['vanneross']\", 'none', 'none', \"['deanforestarc', 'deanjnorris']\", 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', \"['dearleahmichele']\", 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', \"['repdavidscott', 'scottscottlaw']\", 'none', 'none', 'none', \"['gavinverhey']\", 'none', 'none', 'none', 'none', 'none', 'none', \"['michelleshapiro']\", 'none', 'none', \"['deborahlshelton', 'deborahashelton', 'deborahjshelton']\", \"['paulmsherman', 'rsherman_37']\", 'none', \"['jmshowalter']\", \"['ankitstivastava', '_ankits']\", 'none', 'none', 'none', 'none', \"['lisacsinger', 'lisamsinger']\", 'none', 'none', ['jeffskinner', 'blocksrey'], 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', ['smintyschiffer', 'oschiffey'], 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', ['davidtafuri'], 'none', 'none', 'none', 'none', ['lyricthompson'], 'none', 'none', 'none', ['jacksondtoof'], 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', ['kaar61'], ['thedarkprowler'], 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', ['samwebb1876', 'samwebb77'], ['richie_recovery'], 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', ['davidlat', 'davidzapolsky'], 'none', 'none', 'none', 'none', ['yearwoodjose'], 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none', 'none']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lawyerurl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k1pVQ25a5Fui",
        "outputId": "0eaf45bd-d957-4231-acec-22502f90b07c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['https://twitter.com/chuckadamsar',\n",
              " 'https://twitter.com/adamsandreese/status/1755574837865570464',\n",
              " 'https://twitter.com/adam_cannon?lang=en',\n",
              " 'https://twitter.com/drlukeallen?lang=en',\n",
              " 'https://twitter.com/timanzenberger?lang=en',\n",
              " 'https://twitter.com/WTMAtkinson',\n",
              " 'https://twitter.com/la_baio?lang=en',\n",
              " 'https://twitter.com/adamsandreese/status/1755574837865570464',\n",
              " 'https://twitter.com/dbernstein?lang=en',\n",
              " 'https://twitter.com/davidlbernstein?lang=en',\n",
              " 'https://twitter.com/cbbonner?lang=en',\n",
              " 'https://twitter.com/adamsandreese/status/948961860904202246?lang=en',\n",
              " 'https://twitter.com/adamsandreese/status/1458868876113059849',\n",
              " 'https://twitter.com/seanbuckley?lang=en',\n",
              " 'https://twitter.com/AttorneyBuckley',\n",
              " 'https://twitter.com/BradleyByrne',\n",
              " 'https://twitter.com/Robertc1970',\n",
              " 'https://twitter.com/paulreindlsd?lang=en',\n",
              " 'https://twitter.com/tnlastcall?lang=en',\n",
              " 'https://twitter.com/RoofCoffeeShop/status/1683885295228293121',\n",
              " 'https://twitter.com/jdavisofficial?lang=en',\n",
              " 'https://twitter.com/ginadtucker?lang=en',\n",
              " 'https://twitter.com/dani_dougs?lang=en',\n",
              " 'https://twitter.com/adamsandreese/status/161868628227137536',\n",
              " 'https://twitter.com/adamduerson?lang=en',\n",
              " 'https://twitter.com/achrisevans/status/749969917055799296?lang=en',\n",
              " 'https://twitter.com/adamsandreese/status/1762604363405480131',\n",
              " 'https://twitter.com/AndruFreeman']"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import xlsxwriter\n",
        "import xlrd\n",
        "from collections import OrderedDict\n",
        "import tweepy\n",
        "import datetime\n",
        "import time\n",
        "\n",
        "# API Auth 받기\n",
        "client = tweepy.Client(\n",
        "    bearer_token = \"AAAAAAAAAAAAAAAAAAAAABF0rgEAAAAA6fb3wEWef68E5ibNkS3NYtmRM9I%3D9ehXrnUMBnYNCmuQUdGdTbvoV8saXM9x3IqzFV36GS1IRRSeh2\",\n",
        "    consumer_key= \"OB3FBQsfgBtLxsmY8zf1McMLV\",\n",
        "    consumer_secret= \"Eg8Zwg7MsnFWyNLY92iNKJ74tylqjnWT2VsdepmpOn6oo71VaH\",\n",
        "    access_token= \"1616524542880481285-lo2Dl0Ke9ImLRd1zdEUvQT9i8vfCQS\",\n",
        "    access_token_secret= \"olX7JuenBPyE93732LG29QUCWSCmZabrgfZ9gy818IGzf\",\n",
        "    wait_on_rate_limit=True\n",
        ")\n",
        "\n",
        "auth = tweepy.OAuthHandler(\"OB3FBQsfgBtLxsmY8zf1McMLV\", \"Eg8Zwg7MsnFWyNLY92iNKJ74tylqjnWT2VsdepmpOn6oo71VaH\")\n",
        "auth.set_access_token(\"1616524542880481285-lo2Dl0Ke9ImLRd1zdEUvQT9i8vfCQS\",\n",
        "                      \"olX7JuenBPyE93732LG29QUCWSCmZabrgfZ9gy818IGzf\")\n",
        "api = tweepy.API(auth)\n",
        "\n",
        "# 트위터 계정 Description 받아내는 코드\n",
        "for i in twitter_id:\n",
        "  response = client.get_user(username = i, user_fields = [\"description\", \"public_metrics\", \"name\", \"url\"])\n",
        "  user = response.data\n",
        "  try:\n",
        "    values = {\"user_id\": user.id, \"username\": user.username, \"description\": user.description, \"name\": user.name, \"url\": user.url}\n",
        "    values.update(user.public_metrics)\n",
        "    ser = pd.Series(values)\n",
        "    description = ser[2]\n",
        "    name = ser[3]\n",
        "    url = ser[4]\n",
        "    print(\"{} -\".format(name), \"{}:\".format(i), description, unshorten_url(url), \"\\n\")\n",
        "  except Exception as error:\n",
        "    print(error)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0NozYfu2vEpP",
        "outputId": "f5d65da9-725b-4d4a-d29b-36ddb7c88c03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Charles P. Adams, Jr - chuckadamsar: Husband, Father, Grandfather, Georgetown Grad and Hoya fan. Former Managing Partner at Adams and Reese LLP. Sharing miscellaneous Observations. https://www.adamsandreese.com/ \n",
            "\n",
            "Adam Cannon - adam_cannon: Director of Legal @TheSun and a photographer \n",
            "\n",
            "#followme on Insta: https://t.co/mPQeKqHWRf https://linktr.ee/Thetravellingbrief \n",
            "\n",
            "Luke Allen - drlukeallen: Health systems policy & practice. Fellow @LSHTM | Oxford GP | Consultant @WHO & @WorldBank | Board @BJGPjournal | Prev Harvard/MIT. Fighting social injustice https://drlukeallen.mystrikingly.com/ \n",
            "\n",
            "Tim Anzenberger - timanzenberger: Partner at Adams and Reese LLP: Bankruptcy, Commercial Litigation, and Appellate Practice. Mississippi/North Carolina. None \n",
            "\n",
            "William Atkinson - WTMAtkinson: Assistant Editor @ConHome\n",
            "Tory Leninist and voice of yoof \n",
            "'A total Tory BNOC' - @Tatlermagazine\n",
            "william@conservativehome.com None \n",
            "\n",
            "Lauren Baio - la_baio: Florida and Washington, D.C. licensed attorney with a passion for ocean conservation. None \n",
            "\n",
            "David S. Bernstein - dbernstein: Mitt Romney once tried to wager $10,000 that I got something wrong. Freelance journalist, covering local, state, & national politics and policy. https://davidsbernstein.substack.com/ \n",
            "\n",
            "David Bernstein - davidlbernstein: Founder of Jewish Institute for Liberal Values | Book: Woke Antisemitism - How a Progressive Ideology Harms Jews | Buy on Amazon: https://t.co/NiYmOlFNLH https://jilv.org/ \n",
            "\n",
            "C. Britton Bonner - cbbonner:  https://www.adamsandreese.com/ \n",
            "\n",
            "Sean Buckley - seanbuckley: Business attorney in #Dallas #FortWorth. I post about advertising, digital marketing, beer, wine, law, privacy, urbanism, and development. https://www.dykema.com/people/sean-m-buckley.html \n",
            "\n",
            "Sean Buckley ⚖️🌊✍🏿 - AttorneyBuckley: Husband| #Author; O’Connor’s Federal Criminal Rules & Codes 2024-2025. ~Defense Attorney ⚖️War Eagle 🏈#BuckleyCriminalDefenseAttorney #WritingCommunity https://www.seanbuckleylaw.com/ \n",
            "\n",
            "Bradley Byrne - BradleyByrne: Dad, Grandfather, and proud Alabamian fighting for conservative values. None \n",
            "\n",
            "Rob Campbell - Robertc1970: Positive pessimist. Also a Forest fan. Probably connected. Ex-Cynic, Wieden+Kennedy & R/GA. Now at Colenso, Weigel/Campbell & Metallica. https://robcampbell.co/ \n",
            "\n",
            "Paul Reindl - paulreindlsd: Executive Producer for @BenAndWoods https://www.audacy.com/973thefansd/authors/paul-reindl \n",
            "\n",
            "Will Cheek - tnlastcall: Will Cheek is the go-to source for liquor licensing in Tennessee and blogs about liquor at https://t.co/BX0n6OguNT None \n",
            "\n",
            "RoofersCoffeeShop® - RoofCoffeeShop: We are a community of #roofing professionals that share ideas, tell stories, research, sell stuff and find help. We are Where The Roofing Industry Meets! https://www.rooferscoffeeshop.com/ \n",
            "\n",
            "Jonathan Davis - jdavisofficial: https://t.co/qQWUu7ib2c https://www.jonathandavis.com/ \n",
            "\n",
            "Gina Tucker - ginadtucker: plant-based food marketer None \n",
            "\n",
            "Danielle Douglas - dani_dougs: Law Student, University of Calgary. Program Coordinator, Pro Bono Students Canada @pbsccalgary None \n",
            "\n",
            "Adam Duerson - adamduerson: Editor-In-Chief, @FOS. Formerly: Exec Editor, @SInow. I got “steamrollered” changed to “steamrolled” in the SI style guide ✊  adam.duerson@frontofficesports.com https://frontofficesports.com/ \n",
            "\n",
            "Chris Evans - achrisevans: Host of The Virgin Radio Breakfast Show with Sky, creator of CarFest, custodian of 500 Words. But mostly punching way above his weight in the marriage dept. https://virginradio.co.uk/shows/the-chris-evans-breakfast-show \n",
            "\n",
            "Andrew Freeman - AndruFreeman: Official Twitter for #AndrewFreeman Frontman for #LastInLine. Former guitarist for #Offspring - Former singer #LynchMob #DevilsHand https://www.andrewfreemanmusic.com/ \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Possible word to check whether the user is a Lawyer: \"legal\", \"LLP\", \"company name\", \"attorney\", \"pro bono\", \"probono\","
      ],
      "metadata": {
        "id": "RehRqe1_4mVL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 쓰레기통\n",
        "\n",
        "# Step 2\n",
        "\n",
        "# 엑셀파일 불러오기\n",
        "file_path = \"/content/drive/MyDrive/Lawyers/Accounts/AdamandReese/Adam and Reese LLP Twitter.csv\"\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "input_column = df.columns[1]\n",
        "output_column = df.columns[2]\n",
        "# print(namelist)\n",
        "\n",
        "# 리스트안에 변호사 이름별로 검색하여 트위터 계정 찾기\n",
        "for i in input_column[:]:\n",
        "  try:\n",
        "    searchs = '{} {} \"Twitter\"'.format(company, i)\n",
        "    results = s(searchs, sleep_interval = 1, num_results = 1)\n",
        "    for r in results:\n",
        "      if r.startswith(twitterurl):\n",
        "        lawyerurl.append(r)\n",
        "    input_column.remove(i)\n",
        "  except Exception as error:\n",
        "    print(\"An exception occured:\", error)\n",
        "    break\n",
        "\n",
        "print(lawyerurl)\n",
        "\n",
        "# Assuming the input is in the first column (A) and we want to write the output to the second column (B)\n",
        "# Modify this as per your specific requirements\n",
        "input_column = df.columns[0]  # or df.columns[0] if you want to use the first column dynamically\n",
        "output_column = df.columns[1]  # or df.columns[1] if you want to use the second column dynamically\n",
        "\n",
        "# Process each input and store the result in a new list\n",
        "outputs = []\n",
        "for input_value in df[input_column]:\n",
        "    # Replace the following line with your actual processing logic\n",
        "    output_value = process_input(input_value)  # Example function to process input\n",
        "    outputs.append(output_value)\n",
        "\n",
        "# Add the results to the dataframe\n",
        "df[output_column] = outputs\n",
        "\n",
        "# Write the updated dataframe back to the Excel file\n",
        "df.to_csv(file_path, index=False)\n",
        "\n",
        "\n",
        "\n",
        "#__________________________________________________________________________ Step 2\n",
        "\n",
        "# 엑셀파일 불러오기\n",
        "file_path = \"/content/drive/MyDrive/Lawyers/Accounts/AdamandReese/Adam and Reese LLP Twitter.csv\"\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "namelist = newdf['lawyer name'].tolist()\n",
        "# print(namelist)\n",
        "\n",
        "# 리스트안에 변호사 이름별로 검색하여 트위터 계정 찾기\n",
        "for i in namelist[:]:\n",
        "  try:\n",
        "    searchs = '{} {} \"Twitter\"'.format(company, i)\n",
        "    results = s(searchs, sleep_interval = 1, num_results = 1)\n",
        "    for r in results:\n",
        "      if r.startswith(twitterurl):\n",
        "        lawyerurl.append(r)\n",
        "    namelist.remove(i)\n",
        "  except Exception as error:\n",
        "    print(\"An exception occured:\", error)\n",
        "    break\n",
        "\n",
        "print(lawyerurl)\n",
        "\n",
        "# # 회사 공식 트위터 계정 리스트에서 모두 제거\n",
        "# url_to_remove = 'https://twitter.com/adamsandreese?lang=en'\n",
        "\n",
        "# if url_to_remove in lawyerurl:\n",
        "#   lawyerurl.remove(url_to_remove)\n",
        "\n",
        "# try:\n",
        "#   lawyerurl.remove(url_to_remove)\n",
        "# except ValueError:\n",
        "#   print(f\"The URL was not found in the list.\")\n",
        "\n",
        "# print(lawyerurl)\n",
        "\n",
        "# 회사 공식 트위터 계정 리스트에서 모두 제거\n",
        "url_to_remove = 'https://twitter.com/adamsandreese?lang=en'\n",
        "\n",
        "lawyerurl = [item for item in lawyerurl if item != 'https://twitter.com/adamsandreese?lang=en']\n",
        "\n",
        "print(lawyerurl)\n",
        "\n",
        "# 트위터 결과 및 남은 변호사 따로 엑셀 파일로 저장\n",
        "leftover = pd.DataFrame(namelist)\n",
        "lawyertwitterurl = pd.DataFrame(lawyerurl)\n",
        "\n",
        "# 회사에 맞춰 경로 변경 할 것\n",
        "leftover.to_csv(\"/content/drive/MyDrive/Lawyers/Accounts/AdamandReese/leftover{}.csv\".format(number_count))\n",
        "lawyertwitterurl.to_csv(\"/content/drive/MyDrive/Lawyers/Accounts/AdamandReese/TwitterUrl{}.csv\".format(number_count))\n",
        "\n",
        "number_count += 1\n",
        "\n",
        "# 엑셀파일로 저장한 트위터 URL 불러오기\n",
        "\n",
        "twitterurlpath = \"/content/drive/MyDrive/Lawyers/Accounts/AdamsandReese/ARTwitterUrl.csv\"\n",
        "df = pd.read_csv(twitterurlpath)\n",
        "columns = [\"0\"]\n",
        "newdf = df[columns]\n",
        "\n",
        "twitterurl = newdf['0'].tolist()\n",
        "twitterurl\n",
        "\n",
        "# 엑셀파일로 저장한 남은 변호사들 불러오기\n",
        "\n",
        "leftoverpath = \"/content/drive/MyDrive/Lawyers/Accounts/AdamsandReese/ARleftover.csv\"\n",
        "df = pd.read_csv(leftoverpath)\n",
        "columns = [\"0\"]\n",
        "newdf = df[columns]\n",
        "\n",
        "leftover = newdf['0'].tolist()\n",
        "leftover\n",
        "\n",
        "# 엑셀파일에 저장한 남은 변호사들 불러서 다시 트위터 계정 찾을 때 돌릴 수 있는 코드\n",
        "import pandas as pd\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from googlesearch import search as s\n",
        "import re\n",
        "\n",
        "working = []\n",
        "company = \"Adam and Reese LLP\"\n",
        "twitterurl = \"https://twitter.com/\"\n",
        "\n",
        "for i in leftover[:]:\n",
        "  try:\n",
        "    searchs = '{} {} \"Twitter\"'.format(company, i)\n",
        "    results = s(searchs, sleep_interval = 1, num_results = 1)\n",
        "    for r in results:\n",
        "      if r.startswith(twitterurl):\n",
        "        working.append(r)\n",
        "    leftover.remove(i)\n",
        "  except Exception as error:\n",
        "    print(\"An exception occured:\", error)\n",
        "\n",
        "# 회사 공식 트위터 계정 리스트에서 모두 제거\n",
        "working = [item for item in working if item != 'https://twitter.com/adamsandreese?lang=en']\n",
        "\n",
        "print(working)\n",
        "\n",
        "\n",
        "# 트위터 링크에서 트위터 ID 추출\n",
        "twitter_id = []\n",
        "pattern = r'\\d{19}'\n",
        "patterns = r'\\d{18}'\n",
        "for i in lawyerurl:\n",
        "  i = i.replace(\"https://twitter.com/\", \"\")\n",
        "  i = i.replace(\"?lang=en\",\"\")\n",
        "  i = i.replace(\"/status/\",\"\")\n",
        "  i = re.sub(pattern, \"\", i)\n",
        "  i = re.sub(patterns, \"\", i)\n",
        "  twitter_id.append(i)\n",
        "\n",
        "print(twitter_id)\n",
        "\n",
        "\n",
        "# 회사 공식 트위터 계정 리스트에서 모두 제거\n",
        "twitter_id = [item for item in twitter_id if item != 'adamsandreese']\n",
        "\n",
        "print(twitter_id)"
      ],
      "metadata": {
        "id": "buf-0uSRwyJN",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}